# -*- coding: utf-8 -*-
"""NormalizationAmazonFoods.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WBMh5zAp1bJIlQ0bQ183wE3mx-Rji7Ah
"""

import pandas as pd

file_path = "/content/drive/MyDrive/Datasets Normalization/Amazon Foods/Amazonfoods.csv"

df = pd.read_csv(file_path)

df.dropna(how='all', inplace=True)

productId_map = {}
userId_map = {}
tag_map = {}

product_counter = 1
user_counter = 1000000
tag_counter = 2000000

def normalize_and_get_tag_ids(text):
    global tag_counter
    words = [word.strip().lower() for word in text.split()]
    tag_ids = []
    normalized_words = []

    for word in words:
        if word not in tag_map:
            tag_map[word] = tag_counter
            tag_counter += 1
        tag_ids.append(str(tag_map[word]))
        normalized_words.append(word.capitalize())

    return ', '.join(normalized_words), ', '.join(tag_ids)

for index, row in df.iterrows():
    productId = row['productId']
    if productId not in productId_map:
        productId_map[productId] = product_counter
        product_counter += 1
    df.at[index, 'productId'] = productId_map[productId]

for index, row in df.iterrows():
    userId = row['userId']
    if userId not in userId_map:
        userId_map[userId] = user_counter
        user_counter += 1
    df.at[index, 'userId'] = userId_map[userId]

df[['Stext', 'tagId']] = df['Stext'].apply(normalize_and_get_tag_ids).apply(pd.Series)

output_file_path = '/content/drive/MyDrive/Datasets Normalization/Amazon Foods/processed_Amazonfoods.csv'
df.to_csv(output_file_path, index=False)

print("Done!")

